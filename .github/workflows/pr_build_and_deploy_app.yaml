# Description
##############
# Buid and deploy WebAPI as single pod service to AKS
# Triggerred automatically by pull request that targets main bra
##############
# input parameters
# SECRETS: 
#    AZURE_NUGET_TOKEN - token to be used during the app building and releasing to connect to the ADO Artifacts NuGet storage 
#    ACR_URL - azure container registry login server in format "contoso.azurecr.io"  without schema name 
#    ACR_USERNAME - azure cotainer registry username
#    ACR_PASSWORD - azure container registry password
#    
#    AZURE_CREDENTIALS - azure credentials in format ""
#    CLUSTER_NAME  - name of AKS cluster
#    RESOURCE_GROUP - azure resource groups 

name: Build & Deploy Web Api
on: 
 pull_request:
   branches:
    - main  # branch that pr targets 
   paths:
   # restrict changes to only specific path to avoid deploying any other service
    - 'src/Services/Services.BackendApi/**' 

env:
  DOCKER_IMAGE_NAME: backendapi
  CLUSTER_NAMESPACE: b2kapp # K8s namespace to be used in deployment
  SERVICE_NAME: backendapi
  ACR_URL: xtestacr113.azurecr.io
  # wherer or not deploy Ingress for the service. 
  # If service should be tested with direct HTTP call the Ingress should be deployed
  # if service should be tested in conjunction with other ones 
  #   e.g. backend API service should be tested by sending request to the Front-end API service [FrontendAPI->--(1-N Other Services)-> BackendAPI--(1-N)->Other Services]
  #    it make sence to avoid deploying Ingress for backend api 
  ENABLE_INGRESS: false
  # to make repetative builds, that triggered against the same pull request that has same commits,
  # deterministic and cleanup K8s resources deployed in previous build run use the last commit SHA
  # instead of the merge commit SHA that is in the  GITHUB_SHA env variable  or ${{ github.sha}} action context variable
  # if new commits were added to PR between the two subsequent builds the "new last commit SHA" appears so no K8s resource cleanup made
  LAST_COMMIT_SHA: ${{ github.event.pull_request.head.sha }}


permissions:
# required by the Azure Login action and kubernetes deploy https://github.com/Azure/k8s-deploy
  id-token: write 
  contents: read
  actions: read

# cancel all other instances of the current worflow that are running 
# for the same branch e.g.  
concurrency: 
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build_and_deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout sources
        uses: actions/checkout@v3
        with:
         fetch-depth: 0

        # login to Azure with in advance created creds
        # see how to create app, service principal and assign service principal on azure subscription with Contributor role
        # https://learn.microsoft.com/en-us/azure/developer/github/connect-from-azure?tabs=azure-cli%2Cwindows#create-an-azure-active-directory-application-and-service-principal
      - name: Azure Login 
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      # set Kubectl context  see more https://github.com/Azure/aks-set-context#example
      - name: Set Azure Context  
        uses: azure/aks-set-context@v3
        with:          
          cluster-name: ${{ secrets.CLUSTER_NAME }}
          resource-group: ${{ secrets.RESOURCE_GROUP }}      

        # since Projects requre access to  NelNet ADO NuGet Artifacts feed
        # nuget.config file should be modified and nuget access token replaced with valid one taken from secrets
      - name: Replace NuGet Token
        run: | 
              (Get-Content './src/Services/Services.BackendApi/nuget.config' -Raw) -Replace 'AZURE_NUGET_TOKEN','${{secrets.AZURE_NUGET_TOKEN}}' | `
              Set-Content './src/Services/Services.BackendApi/nuget.config'
        shell: pwsh  

      - name: Authenticate in  Azure container registry        
        uses: azure/docker-login@v1
        with:
          login-server: ${{ env.ACR_URL }}
          username: ${{ secrets.ACR_USERNAME }}
          password: ${{ secrets.ACR_PASSWORD }}
      - name: Build docker image
        id: build_docker_image               
        run: |
             <#
             create docker image and push it to ACR 
             image tag has format <ACR_URL>/<ImageName>:<ImageTag> e.g. myImages.azureacr.io/backendapi:12345
             script below creates image and tags it with first 7 digits of github PR SHA (The commit SHA that triggered the workflow. ) 
             if instead of github commit SHA the branch name should be used to tag docker image it is possible but all special characters should be 
             replaced with empty string e.g.   
              "${{github.ref}}" -replace "[^a-zA-Z0-9 -]", "" 
             #> 

             $imageUrl="$($Env:ACR_URL)/$($Env:DOCKER_IMAGE_NAME)" 
             $imageTag= $($Env:LAST_COMMIT_SHA.SubString(0,7))
             $fullImageUrl="$($imageUrl):$($imageTag)"

             echo "Full ACR image url with tag: $fullImageUrl"

             docker build -f './src/Services/Services.BackendApi/Dockerfile' --force-rm -t "$fullImageUrl" "$($Env:GITHUB_WORKSPACE)/src/Services"
             docker push "$fullImageUrl"

             echo "::echo::on"

             echo "::set-output name=image_url::$imageUrl" # expose full url on acr and docker image  
             echo "::set-output name=image_tag::$imageTag" # expose docker image tag             

             echo "::echo::off"

        shell: pwsh

      - name: Create rlease name
        id: release-name
        run: |
              <#
                generate release name as <servicename>-<First7SymbolsOfLastCommitSHA>    
              #>
              $releaseName = "${{env.SERVICE_NAME}}-$($Env:LAST_COMMIT_SHA.SubString(0,7))"
              echo "Release name:  $releaseName"
              echo "::echo::on"
              echo "::set-output name=result::$releaseName"
              echo "::echo::off"
        shell: pwsh

      - name: Prepare HEML chart
        uses: azure/k8s-bake@v1
        id: bake_helm
        with:
            renderEngine: 'helm'   
            helmChart: './src/Services/Services.BackendApi/charts/backendapi/'
            releaseName: ${{steps.release-name.outputs.result}} # e.g. backendapi-b123asd  <servicename>-SHA
            silent: false # set to true for suppress action log output
            overrides: |
              image.repository:${{ steps.build_docker_image.outputs.image_url }}
              image.tag:${{ steps.build_docker_image.outputs.image_tag }}
              fullnameOverride:${{steps.release-name.outputs.result}}
              image.pullPolicy:"Always"
              ingress.enabled:${{env.ENABLE_INGRESS}}   
      
      # Deploy app to AKS - do not use azure/k8s-deploy since it pollutes K8s resources
      # with annotations that cannot be turned off 
      - name: Deploy to AKS
        run: | 
              # remove any s
              kubectl delete -f ${{ steps.bake_helm.outputs.manifestsBundle }} --namespace ${{env.CLUSTER_NAMESPACE}} --ignore-not-found=true  --insecure-skip-tls-verify --wait=true  
              kubectl apply -f ${{ steps.bake_helm.outputs.manifestsBundle }} --insecure-skip-tls-verify --namespace ${{env.CLUSTER_NAMESPACE}}

              # optionally to make sure that deployment created pod via replicaset and pods are running can wait for it 
              kubectl wait pods -n ${{env.CLUSTER_NAMESPACE}} -l "app.kubernetes.io/instance=${{steps.release-name.outputs.result}}" --for condition=Ready --timeout=90s
        shell: pwsh 


        # annotate pods deployed in "Deploy to AKS" 
        # with the Bridge to Kubernetes  
      - name: Add routing labels
        run: |
              <#
                 Annnotate pod with Bridge To Kubernetes label
               #>

              echo "Show pods that will be annotated with B2K labels"

              kubectl get pods --selector="app.kubernetes.io/instance=${{steps.release-name.outputs.result}}"  --namespace ${{ env.CLUSTER_NAMESPACE  }}  

              echo " - Labeling pod that have app.kubernetes.io/instance=${{steps.release-name.outputs.result}} to route traffic from ${{env.SERVICE_NAME}} "
              
              # Apply label to the new pod deployed by HELM chart and marked as app.kubernetes.io/instance=<service-githubSHA>
              # label will tell B2K to route requests from the original service 

              kubectl label pods --selector="app.kubernetes.io/instance=${{steps.release-name.outputs.result}}" "routing.visualstudio.io/route-from=${{env.SERVICE_NAME}}"  --namespace ${{ env.CLUSTER_NAMESPACE  }} --overwrite=true  

              # Annotate POD with HTTP routing header to route requests to this POD when header has specific value 

              echo "- Annotating pod that have app.kubernetes.io/instance=${{steps.release-name.outputs.result}}" 
              echo "- to accept traffic when HTTP header kubernetes-route-as has value ${{steps.release-name.outputs.result}}"

              kubectl annotate pods  --selector="app.kubernetes.io/instance=${{steps.release-name.outputs.result}}" "routing.visualstudio.io/route-on-header=kubernetes-route-as=${{steps.release-name.outputs.result}}"  --namespace ${{ env.CLUSTER_NAMESPACE }}  --overwrite=true
        shell: pwsh

      - name:  Return workflow output result
        id: workflow_result
        run : |
              <#
               Get ingress URL if the ingress was enabled for service or just value of the HTTP routing header 'kubernetes-route-as'  
              #>

              $ingressEnabled = "${{env.ENABLE_INGRESS}}"
              if ([boolean]$ingressEnabled -eq $False )
              {
                $ingressUrl="";
                echo "::notice ::Service was deployed with the disabled Ingress controller no service URL will be publicy available. Service"
                echo "::notice ::Service can be accessed indirectly with HTTP header 'kubernetes-route-as:${{steps.release-name.outputs.result}}'"
              }
              else
              {
                $ingressUrl = $(kubectl get ingresses -n ${{ env.CLUSTER_NAMESPACE  }}  -o=custom-columns=HOST:.spec.rules[0].host  | Select-String -Pattern "${{steps.release-name.outputs.result}}*" -List))

                echo "Service exposed via Ingress URL: $ingressUrl"
              }
              
              echo "::set-output name=ingress_url::$ingressUrl"
              echo "::set-output name=routing_header::${{steps.release-name.outputs.result}}"
        shell: pwsh

          
          
        
  
  